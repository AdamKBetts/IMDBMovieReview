{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b313cc4d-1d74-42ab-8a8d-2d39a10610da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment\n",
      "0  One of the other reviewers has mentioned that ...  positive\n",
      "1  A wonderful little production. <br /><br />The...  positive\n",
      "2  I thought this was a wonderful way to spend ti...  positive\n",
      "3  Basically there's a family where a little boy ...  negative\n",
      "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import Dataset\n",
    "df = pd.read_csv('C:/Users/akbet/imdb_dataset.csv')\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values and data types\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e024db4-fbb4-45d0-9264-404598fb8284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akbet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    one review mention watch oz episod hook right ...\n",
      "1    wonder littl product film techniqu unassum old...\n",
      "2    thought wonder way spend time hot summer weeke...\n",
      "3    basic famili littl boy jake think zombi closet...\n",
      "4    petter mattei love time money visual stun film...\n",
      "Name: cleaned_review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize the stemmer and stopwords\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags (if any)\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # Convert to lowercase and split into words\n",
    "    words = text.lower().split()\n",
    "    # Remove stopwords and apply stemming\n",
    "    processed_words = [ps.stem(word) for word in words if word not in stop_words]\n",
    "    return \" \".join(processed_words)\n",
    "\n",
    "# Apply the preprocessing function to the 'review' column\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "# Display a sample of the cleaned text\n",
    "print(df['cleaned_review'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ec7ac5-5aca-4847-8a07-5c41c5046343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Seperate features (X) and target (y)\n",
    "X = df['cleaned_review']\n",
    "y = df['sentiment']\n",
    "\n",
    "# Map the sentiment labels to 1s and 0s\n",
    "y = y.map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split the data into training and testing sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "# We'll limit the number of features to the 5000 most frequent words\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit the vectorizer on the training data and transform both training and testing data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf24eada-65b2-48c8-a569-6c1ec7c0f5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Model Performance Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      7411\n",
      "           1       0.88      0.90      0.89      7589\n",
      "\n",
      "    accuracy                           0.89     15000\n",
      "   macro avg       0.89      0.89      0.89     15000\n",
      "weighted avg       0.89      0.89      0.89     15000\n",
      "\n",
      "Overall Accuracy: 0.8865\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "sentiment_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the TF-IDF training data\n",
    "sentiment_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = sentiment_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"--- Model Performance Report ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the overall accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a978d6e-7b8c-4af2-9e4b-0304d8fcfa00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Top 20 Words Predicting Positive Sentiment ---\n",
      "           word  coefficient\n",
      "1954      great     6.962201\n",
      "1546      excel     6.833022\n",
      "3250    perfect     5.279262\n",
      "1471      enjoy     5.200069\n",
      "2672       love     4.819951\n",
      "540   brilliant     4.793761\n",
      "140        amaz     4.581360\n",
      "404        best     4.564228\n",
      "1637    favorit     4.428023\n",
      "2105     hilari     4.191177\n",
      "1619    fantast     3.921566\n",
      "371      beauti     3.802644\n",
      "4348     superb     3.758992\n",
      "1145    definit     3.737979\n",
      "4529      today     3.692005\n",
      "2101     highli     3.682685\n",
      "1816        fun     3.672608\n",
      "4871       well     3.591211\n",
      "3251  perfectli     3.389761\n",
      "4557      touch     3.368544\n",
      "\n",
      "--- Top 20 Words Predicting Negative Sentiment ---\n",
      "            word  coefficient\n",
      "4952       worst    -9.862273\n",
      "4842        wast    -8.742034\n",
      "295           aw    -7.621664\n",
      "315          bad    -7.136686\n",
      "491         bore    -7.026217\n",
      "4463     terribl    -5.883986\n",
      "3354        poor    -5.781631\n",
      "1245  disappoint    -5.604252\n",
      "1599        fail    -5.296256\n",
      "3058        noth    -5.169958\n",
      "1357        dull    -4.965287\n",
      "2159     horribl    -4.951941\n",
      "3355      poorli    -4.874089\n",
      "4950        wors    -4.791614\n",
      "4358      suppos    -4.725445\n",
      "4682    unfortun    -4.419108\n",
      "3844        save    -4.356245\n",
      "175        annoy    -4.309976\n",
      "3724     ridicul    -4.270368\n",
      "2525        lack    -4.244588\n"
     ]
    }
   ],
   "source": [
    "# Get the feature names from the TF-IDF vectorizer\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get the model coefficients\n",
    "coefficients = sentiment_model.coef_.flatten()\n",
    "\n",
    "# Create a DataFrame to link words and their coefficients\n",
    "word_coefficients = pd.DataFrame({'word': feature_names, 'coefficient': coefficients})\n",
    "\n",
    "# Sort by coefficient to find the most positive and negative words\n",
    "top_positive_words = word_coefficients.sort_values(by='coefficient', ascending=False).head(20)\n",
    "top_negative_words = word_coefficients.sort_values(by='coefficient', ascending=True).head(20)\n",
    "\n",
    "print(\"--- Top 20 Words Predicting Positive Sentiment ---\")\n",
    "print(top_positive_words)\n",
    "print(\"\\n--- Top 20 Words Predicting Negative Sentiment ---\")\n",
    "print(top_negative_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
